# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

# Defines the trigger for the pipeline.
# This pipeline will only run when changes are made on the master branch and in the 'global' path.
trigger:
  branches:
    include:
    - master
  paths:
    include:
    - global/*
    exclude:
    - 'global/*.txt'
    - 'global/*.md'
    - 'global/*.js'
    - 'global/*.json'
    - 'global/*.xml'
    - 'global/*.yml'
    - 'global/*.py'
    - 'global/*.java'
    - 'global/*.c'
    - 'global/*.cpp'
    - 'global/*.h'
    - 'global/*.hpp'
    - 'global/*.html'




# Specifies the pool of virtual machines to use for the pipeline.
# In this case, we're using the latest Ubuntu VM image.
pool:
  vmImage: ubuntu-latest

stages:
- stage: PreparationStage
  jobs:

  - job: 'PreparationJob'

    steps:
    - checkout: self
      fetchDepth: 0 # 2 # Fetches the last 2 commits (defaults to no limit) where we need to compare only the last commits to make a decision

    # as of now it is working only file-by-file, meaning, the pipeline runs for every single commit containint jsut one file
    - script: |
        # Get the list of files changed in the last commit.
        FILES=$(git diff --name-only HEAD~1 HEAD)
        # Store the list in a pipeline variable 'changedFiles'.
        echo "##vso[task.setvariable variable=changedFiles]$FILES"
      displayName: 'Get changed file (trigger)'

    - script: |
        echo $(changedFiles)
      displayName: 'Print the names of changed file'

    # - script: |
    #     cat $(changedFiles)
    #   displayName: 'View content of changedFiles'

    # - script: echo $(Build.SourceVersion)
    #   displayName: 'Print the commit SHA'

    # - script: |
    #     git diff-tree --no-commit-id --name-only -r $(Build.SourceVersion)
    #   displayName: 'List the files changed in the commit'

    - script: |
        git checkout $(Build.SourceVersion)
        contentSHA=$(git hash-object $(changedFiles))
        echo "##vso[task.setvariable variable=contentSHA]$contentSHA"
      displayName: 'Calculate and set the <content SHA>, note - same SHA is stored at ServiceNow for correlation'

    - script: |
        # Check if the changed file(s) is in the 'global' directory.
        # If so, extract the filename and directory parts, and store them as pipeline variables.
        if [[ "$(changedFiles)" == global* ]] && [[ "$(changedFiles)" != *.js ]]; then
          echo "##vso[task.setvariable variable=startsWithGlobal]true"
          LAST_PART=$(basename $(changedFiles))
          echo "##vso[task.setvariable variable=lastPart]$LAST_PART"
          FIRST_PART=${LAST_PART:0:-33}
          echo "##vso[task.setvariable variable=firstPart]$FIRST_PART"
        else
          # If not, set the 'startsWithGlobal' pipeline variable to 'false' and exit the script.
          echo "##vso[task.setvariable variable=startsWithGlobal]false"
          exit 1
        fi
      displayName: 'Check if changedFiles starts with "global" and does not end with ".js"'


    - script: |
        # Install the lxml Python library, used for parsing XML files.
        pip install lxml
      displayName: 'Install lxml used for parsing JS from XML file'


    - script: |
        # Use Python to parse the XML file and extract the content inside <script> tags.
        # The content is then hashed, stored in a pipeline variable, and written to a new .js file.
        # The original <script> tag in the XML file is replaced with the hash value.
        python -c "
        import lxml.etree as ET
        import hashlib
        def remove_cdata_tags(text):
            return text.replace('<![CDATA[', '').replace(']]>', '')
        def hash_content(content):
            return hashlib.sha256(content.encode()).hexdigest()
        parser = ET.XMLParser(remove_blank_text=True)
        tree = ET.parse('$(changedFiles)', parser)
        root = tree.getroot()
        for script in root.iter('script'):
            cdata = script.text  # get CDATA content
            if cdata:
                # print(cdata)
                cdata_content = remove_cdata_tags(cdata)  # remove CDATA tags
                print(cdata_content)
                hash_value = hash_content(cdata_content)  # get SHA-256 hash of the content
                script.text = hash_value  # replace the content of the script tag with the hash value
                print(hash_value)
                # with open('script.js', 'w') as f:
                with open(f'{hash_value}.js', 'w') as f:
                    f.write(cdata_content + '\n')
            # Set an Azure Pipelines variable with the hash value
            print(f'##vso[task.setvariable variable=hashValue]{hash_value}')
        # Write the modified XML to a new file
        tree.write('$(lastPart)', pretty_print=True, xml_declaration=True, encoding='utf-8')
        "
      displayName: 'Extract <script> element from XML and store as separate JS file'






    # - script: |
    #     echo "Print hashValue used as Unique JS file name:"
    #     echo $(hashValue)
    #     echo "Current Directory:"
    #     pwd
    #     echo "List files:"
    #     ls -la
    #     cat $(hashValue).js
    #     cat $(lastPart)
    #   displayName: 'View content of script and ServiceNow object XML'


    - task: ServiceNow-DevOps-Config-Agent-Upload-Config@1
      name: DevOpsConfigXmlUpload
    #  condition: eq(variables['startsWithGlobal'], 'true')
      inputs:
        connectedServiceName: 'snow8'
        applicationName: 'Snow8Demo'
        uploadTarget: 'component'
        configFile: '$(lastPart)'
        namePath: '$(firstPart)'
        dataFormat: 'xml'
        autoValidate: true
        autoCommit: true
        convertPath: true


    - script: |
        echo $(DevOpsConfigXmlUpload.changesetNumber)
      displayName: 'Print DevOpsConfigXmlUpload.changesetNumber'


    - task: ServiceNow-DevOps-Config-Agent-Get-Snapshot@1
      name: DevOpsConfigGetSnapshot
      inputs:
        connectedServiceName: 'snow8'
        applicationName: 'Snow8Demo'
        deployableName: 'TestJS'
        changeSetNumber: '$(DevOpsConfigXmlUpload.changesetNumber)'
        isValidated: true


    - script: |
        echo $(DevOpsConfigGetSnapshot.snapshotName)
      displayName: 'Print DevOpsConfigGetSnapshot.snapshotName'


    - task: ServiceNow-DevOps-Config-Agent-Export-Snapshot@1
      inputs:
        connectedServiceName: 'snow8'
        applicationName: 'Snow8Demo'
        deployableName: 'TestJS'
        exporterName: 'returnESLint'
        dataFormat: 'json'
        saveFile: true
        fileName: 'config_eslint.json'




    - task: CmdLine@2
      inputs:
        script: |
          tree $(Pipeline.Workspace)
      displayName: 'List TREE content'

    # - task: CmdLine@2
    #   inputs:
    #     script: |
    #       echo "View System.DefaultWorkingDirectory that should be: /home/vsts/work/1/s"
    #       echo $(System.DefaultWorkingDirectory)
    #   displayName: 'System.DefaultWorkingDirectory'

    - script: |
        echo "cat - for viewing the file, does not work that is why hexdump is being used"
        hexdump -C $(Pipeline.Workspace)/config_eslint.json
      displayName: 'View DevOps Config config_eslint.json'


    # - script: |
    #     echo "cat - for viewing the file, does not work that is why hexdump is being used"
    #     hexdump -C $(Pipeline.Workspace)/$(lastPart).json
    #   displayName: 'View DevOps Config for XML.json'


    - script: |
        sed -i 's/##-##/\//g' $(Pipeline.Workspace)/config_eslint.json
      displayName: 'Replace strings in JSON file'

    - script: |
        hexdump -C $(Pipeline.Workspace)/config_eslint.json
      displayName: 'View replaced DevOps Config config_eslint.json'


    - script: |
        npm install eslint
      displayName: 'ESLint Install'

    - script: |
        npm install eslint-plugin-servicenow
      displayName: 'ESLint Install eslint-plugin-servicenow'


    - script: |
        echo "Folder creation, just in case if somehow is still missing, could be skipped"
        mkdir -p /home/vsts/work/node_modules/eslint-plugin-algis
        echo '{
          "name": "eslint-plugin-algis",
          "version": "1.0.0",
          "main": "index.js",
          "dependencies": {
            "eslint": "^8.41.0"
          }
        }' > /home/vsts/work/node_modules/eslint-plugin-algis/package.json
      displayName: 'Create ESLint package.json'

    - script: |
        cat /home/vsts/work/node_modules/eslint-plugin-algis/package.json
      displayName: 'View content of package.json'



    - script: |
        echo "module.exports = { rules: {" > /home/vsts/work/node_modules/eslint-plugin-algis/index.js
        echo "'is-valid-encoded-query': require('./lib/rules/is-valid-encoded-query')," >> /home/vsts/work/node_modules/eslint-plugin-algis/index.js
        echo "'no-current-update': require('./lib/rules/no-current-update')}};" >> /home/vsts/work/node_modules/eslint-plugin-algis/index.js
      displayName: 'Create ESLint index.js'

    - script: |
        cat /home/vsts/work/node_modules/eslint-plugin-algis/index.js
      displayName: 'View content of index.js'




    # - script: |
    #     ls /home/vsts/work/node_modules/eslint-plugin-algis
    #   displayName: 'Just validate if created eslint folder exists'

    # - script: |
    #     echo "Printing detailed information about the directory:"
    #     ls -ld /home/vsts/work/node_modules/eslint-plugin-algis
    #     echo "Printing detailed information about the parent directory:"
    #     ls -ld /home/vsts/work/node_modules/
    #   displayName: 'Debugging - Directory information'

    - task: CopyFiles@2
      inputs:
        SourceFolder: '$(System.DefaultWorkingDirectory)/eslint/'
        Contents: '*.js'
        TargetFolder: '/home/vsts/work/node_modules/eslint-plugin-algis/lib/rules/'
        OverWrite: true

    - script: |
        cat /home/vsts/work/node_modules/eslint-plugin-algis/lib/rules/is-valid-encoded-query.js
      displayName: 'Just view content of is-valid-encoded-query.js'



    # This script will first create (or overwrite) the index.js file with the first line, and then append the subsequent lines to the file
    # - script: |
    #     echo "module.exports.rules = {" > /home/vsts/work/node_modules/eslint-plugin-sn_eslint_custom_rule/index.js
    #     echo "  'validate-query': require('./lib/rules/sn_eslint_custom_rule')" >> /home/vsts/work/node_modules/eslint-plugin-sn_eslint_custom_rule/index.js
    #     echo "};" >> /home/vsts/work/node_modules/eslint-plugin-sn_eslint_custom_rule/index.js
    #   displayName: 'Create ESLint index.js'



    - task: CmdLine@2
      inputs:
        script: |
          tree /home/vsts/work/node_modules/eslint-plugin-algis
      displayName: 'List content of eslint-plugin-algis'


    #npx eslint -c $(Pipeline.Workspace)/config_eslint.json $(hashValue).js || true

    # - script: |
    #     (cd /home/vsts/work/node_modules/eslint-plugin-sn_eslint_custom_rule/lib/rules && npm link)
    #     npm link eslint-plugin-sn_eslint_custom_rule
    #   displayName: 'ESLint Linking'

    - script: |
        echo "Printing detailed information about the directory:"
        ls -ld /home/vsts/work/node_modules/eslint-plugin-algis
        echo "Printing detailed information about the parent directory:"
        ls -ld /home/vsts/work/node_modules/
      displayName: 'Debugging: Directory information - LAST'

    - script: |
        ls /home/vsts/work/node_modules/eslint-plugin-algis
        cd /home/vsts/work/node_modules/eslint-plugin-algis
        npm link
      displayName: 'ESLint Linking'


    # NOTE: when taking from GIT, then use: $(System.DefaultWorkingDirectory)/sn_eslint_config.json
    # NOTE: when taking from DevOpsConfig, then use: $(Pipeline.Workspace)/config_eslint.json
    - script: |
        result=$(npx eslint -c $(Pipeline.Workspace)/config_eslint.json $(hashValue).js 2>&1 || true)
        result_base64=$(echo "$result" | base64 | tr -d '\n')
        curl -X POST -H "Content-Type: application/json" -d "{\"contentSha\": \"$(contentSHA)\",\"result\": \"$result_base64\"}" https://operationalrisksolutionsdemo8.service-now.com/api/65300/devsecops
      displayName: 'ESLint Check and Send Results'
      env:
        ESLINT_METADATA_PATH: $(Pipeline.Workspace)/$(lastPart).json

    # - task: CmdLine@2
    #   inputs:
    #     script: |
    #       echo Tree
    #       tree $(Pipeline.Workspace)
    #   displayName: 'List content one more time'


    # - script: |
    #     echo 'const path = require("path");
    #     const modulePath = require.resolve("eslint");
    #     const nodeModulesDir = path.dirname(modulePath);
    #     console.log(nodeModulesDir);' > get_node_modules_dir.js
    #     node get_node_modules_dir.js
    #   displayName: 'Print Node Modules Directory'

    # - task: CmdLine@2
    #   inputs:
    #     script: |
    #       echo Tree
    #       tree /home/vsts/work/node_modules
    #   displayName: 'List node_modules'



    - script: |
        # Install Prettier
        npm install prettier
      displayName: 'Install Prettier'

    - script: |
        # Runs Prettier on JavaScript file and outputs the formatted code to a new file
        npx prettier $(hashValue).js > $(lastPart).js
      displayName: 'Prettier Code Formatting to new JS file'


    - task: ServiceNow-DevOps-Config-Agent-Export-Snapshot@1
      inputs:
        connectedServiceName: 'snow8'
        applicationName: 'Snow8Demo'
        deployableName: 'TestJS'
        exporterName: 'returnDataforNodeName-nowPreview'
        args: |
          {
          	"nodeName": "$(lastPart)"
          }
        saveFile: true
        fileName: '$(lastPart).json'


    - script: |
        # Runs Prettier on JSON file and outputs the formatted code to a new file
        npx prettier $(Pipeline.Workspace)/$(lastPart).json > $(lastPart).json
      displayName: 'Prettier Code Formatting to new JSON file'

    - script: |
        # Move the formatted JavaScript and JSON files to the 'global' directory
        mv $(lastPart).js global/$(lastPart).js
        mv $(lastPart).json global/$(lastPart).json
        ls -al global
      displayName: 'Move formatted files to global directory'

    - script: |
        # Print the final formatted code
        cat global/$(lastPart).js
        cat global/$(lastPart).json
      displayName: 'Print final formatted code for js and json'



    - task: ServiceNow-DevOps-Config-Agent-Export-Snapshot@1
      inputs:
        connectedServiceName: 'snow8'
        applicationName: 'Snow8Demo'
        deployableName: 'TestJS'
        exporterName: 'returnSonarQube'
        dataFormat: 'json'
        saveFile: true
        fileName: 'sonar_qube.json'

    - script: |
        cat -v $(Pipeline.Workspace)/sonar_qube.json
      displayName: 'View content of sonar_qube.json'

    - script: |
        hexdump -C $(Pipeline.Workspace)/sonar_qube.json
      displayName: 'View content of sonar_qube.json using hexdump'



    - pwsh: |
        # Read the json file into a PowerShell object
        $json = Get-Content -Path $(Pipeline.Workspace)/sonar_qube.json | ConvertFrom-Json
        # Extract the value of the keys 'sonar.host.url' and 'sonar.login'
        $url = $json.'sonar.host.url'
        $login = $json.'sonar.login'
        # Print the values to the console
        echo $url
        echo $login
        # If you want to use these values in other steps, you can set them as variables
        echo "##vso[task.setvariable variable=sonarUrl]$url"
        echo "##vso[task.setvariable variable=sonarLogin]$login"
      displayName: 'Extract values from JSON'

    # - script: |
    #     git config --global user.email "$(Build.RequestedForEmail)"
    #     git config --global user.name "$(Build.RequestedFor)"
    #     branchName=$(echo $(Build.SourceBranch) | cut -d "/" -f 3)
    #     git checkout "$branchName"
    #     git add $(lastPart).js
    #     git commit -m "Prettier formatting applied"
    #     git push https://$(sonarLogin)@github.com/$(Build.Repository.Name).git "$branchName"
    #   displayName: 'Commit and push Prettier result'

    # - script: |
    #     git config --global user.email "$(Build.RequestedForEmail)"
    #     git config --global user.name "$(Build.RequestedFor)"
    #     git checkout master
    #     git add $(lastPart).js
    #     git commit -m "Prettier formatting applied"
    #     git push origin master
    #   displayName: 'Commit and push Prettier result'
    #   env:
    #     githubToken: $(sonarLogin)


    - script: |
        ls -al global
        cat global/$(lastPart).json
      displayName: 'Check JSON file'



    - script: |
        git config --global user.email "$(Build.RequestedForEmail)"
        git config --global user.name "$(Build.RequestedFor)"
        git checkout master
        git status
        git add global/$(lastPart).json global/$(lastPart).js
        git status
        git commit -m "Prettier formatting applied for .js and .json"
        git push https://$(sonarLogin)@github.com/$(Build.Repository.Name).git master
      displayName: 'Commit and push Prettier result'





    - script: |
        exit 1
      displayName: 'TMP STOP'

    - task: SonarQubePrepare@4
      inputs:
        SonarQube: 'sonarqubedemo'
        scannerMode: 'CLI'
        configMode: 'manual'
        cliProjectKey: 'algimas'
        cliProjectName: 'algimas'
        cliSources: '$(Pipeline.Workspace)/s'
        extraProperties: |
          sonar.host.url=$(sonarUrl)
          sonar.login=$(sonarLogin)

    - task: SonarQubeAnalyze@4

    - task: SonarQubePublish@4
      inputs:
        pollingTimeoutSec: '300'
